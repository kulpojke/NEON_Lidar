{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdal in /opt/conda/lib/python3.8/site-packages (2.3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDAL wants nupmy <= 1.20.0, you may need to conda update it ```conda update numpy=1.20.1```pip install pdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from API_utils import show_dates, show_files_for_site_date\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "import glob\n",
    "import rasterio\n",
    "from osgeo import gdal\n",
    "import rasterio as rio\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import hashlib\n",
    "import pdal\n",
    "from string import Template\n",
    "import subprocess\n",
    "from dask import delayed, compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "from gdal import GA_ReadOnly\n",
    "\n",
    "ncores = multiprocessing.cpu_count()\n",
    "ncores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'TEAK'\n",
    "productcode = 'DP1.30003.001'\n",
    "tmp_path = '/home/jovyan/tmp'\n",
    "NEON_path = '/home/jovyan/NEON'\n",
    "date = '2018-06'\n",
    "\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "\n",
    "img_path = os.path.join(NEON_path, 'D17_CHM_all_Mask5m_roughFlightline.tif')\n",
    "\n",
    "img = gdal.Open(img_path, GA_ReadOnly)\n",
    "width = img.RasterXSize\n",
    "height = img.RasterYSize\n",
    "gt = img.GetGeoTransform()\n",
    "extent = {}\n",
    "extent['minx'] = gt[0]\n",
    "extent['miny'] = gt[3] + width*gt[4] + height*gt[5] \n",
    "extent['maxx'] = gt[0] + width*gt[1] + height*gt[2]\n",
    "extent['maxy'] = gt[3]\n",
    "img = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_laz_download_info(productcode, site, date):\n",
    "    '''Returns: time of url issueance, list of laz files'''\n",
    "    t0 = time.time()\n",
    "    files = show_files_for_site_date(productcode, site, date)\n",
    "    laz = []\n",
    "    for file in files:\n",
    "        if 'classified_point_cloud_colorized.laz' in file['name']:\n",
    "            laz.append(file)\n",
    "    return(t0, laz)\n",
    "    \n",
    "    \n",
    "def refresh_url(f, t0, productcode, site, date):\n",
    "    '''If too much time has elapsed since url issued, modifies f to contain new url'''\n",
    "    if time.time() - t0 < 3550:\n",
    "        pass\n",
    "    else:\n",
    "        files = show_files_for_site_date(productcode, site, date)\n",
    "        for file in files:\n",
    "            if file['name'] == f['name']:\n",
    "                f['url'] = file['url']\n",
    "                \n",
    "def download_from_NEON_API(f, tmp_path):\n",
    "\n",
    "    attempts = 0 \n",
    "    while attempts < 4:\n",
    "        try:\n",
    "            # get the file \n",
    "            response = requests.get(f['url'], stream=True)\n",
    "            \n",
    "            # raise an error for bad status codes\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            #check the md5 if it exists\n",
    "            if f['md5']:\n",
    "                md5 = hashlib.md5(response.content).hexdigest()\n",
    "                if md5 == f['md5']:\n",
    "                    success = True\n",
    "                    attempts = 4\n",
    "                else:\n",
    "                    fmd5 = f['md5']\n",
    "                    print(f'md5 mismatch on attempt {attempts}')\n",
    "                    success = False\n",
    "                    attempts = attempts + 1\n",
    "            else: \n",
    "                success = True\n",
    "                attempts = 4\n",
    "        except Exception as e:\n",
    "            print(f'Warning:\\n{e}')\n",
    "            success = False\n",
    "            attempts = attempts + 1\n",
    "    # write the file\n",
    "    if success:\n",
    "        fname = os.path.join(tmp_path, f['name'])\n",
    "        with open(fname, 'wb') as sink:\n",
    "            for block in response.iter_content(1024):\n",
    "                sink.write(block)\n",
    "        time.sleep(1)   # this should not be nededed!\n",
    "            \n",
    "    else:\n",
    "        raise Exception('failed to download')\n",
    "        \n",
    "def make_pipe(f, bbox, out_path, resolution=1):\n",
    "    tile = '_'.join(f.rpartition('/')[2].split('_')[4:6])\n",
    "    '''Creates, validates and then returns the pdal pipeline\n",
    "    \n",
    "    Arguments:\n",
    "    bbox       -- Tuple - Bounding box in srs coordintes (default srs is EPSG:3857),\n",
    "                  in the form: ([xmin, xmax], [ymin, ymax]).\n",
    "    outpath   -- String - Path where the CHM shall be saved. Must include .tif exstension.\n",
    "    srs        -- String - EPSG identifier for srs  being used. Defaults to EPSG:3857\n",
    "                  because that is what ept files tend to use.\n",
    "    threads    -- Int - Number os threads to be used by the reader.ept. Defaults to 4.\n",
    "    resolution -- Int or Float - resolution (m) used by writers.gdal\n",
    "    '''\n",
    "    \n",
    "    t = Template('''\n",
    "    {\n",
    "        \"pipeline\": [\n",
    "            {\n",
    "            \"filename\": \"${f}\",\n",
    "            \"type\": \"readers.las\",\n",
    "            \"tag\": \"readdata\"\n",
    "            },\n",
    "            {\n",
    "            \"type\":\"filters.outlier\",\n",
    "            \"method\":\"radius\",\n",
    "            \"radius\":1.0,\n",
    "            \"min_k\":4\n",
    "            },\n",
    "            {\n",
    "            \"type\":\"filters.optimalneighborhood\",\n",
    "            \"min_k\":8,\n",
    "            \"max_k\": 50\n",
    "            },\n",
    "            {\n",
    "            \"type\":\"filters.covariancefeatures\",\n",
    "            \"knn\":10,\n",
    "            \"threads\": 2,\n",
    "            \"feature_set\": \"Anisotropy,DemantkeVerticality,Linearity,Omnivariance,Planarity,Scattering,SurfaceVariation,Verticality\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_Anisotropy.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"Anisotropy\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_DemantkeVerticality.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"DemantkeVerticality\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_Linearity.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"Linearity\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_Omnivariance.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"Omnivariance\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_Planarity.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"Planarity\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_Scattering.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"Scattering\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_SurfaceVariation.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"SurfaceVariation\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            },\n",
    "            {\n",
    "            \"filename\": \"${outpath}/${tile}_Verticality.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\":  \"${resolution}\",\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6,\n",
    "            \"dimension\": \"Verticality\",\n",
    "            \"bounds\": \"${bbox}\"\n",
    "            }\n",
    "        ]\n",
    "    }''')\n",
    "\n",
    "    pipe = t.substitute(f=f, bbox=bbox, outpath=out_path, tile=tile, resolution=resolution)\n",
    "    pipeline = pdal.Pipeline(pipe)\n",
    "    if pipeline.validate():\n",
    "        return(pipeline, tile)\n",
    "    else:\n",
    "        raise Exception('Bad pipeline (sorry to be so ambigous)!')\n",
    "        \n",
    "def download_laz(f, tmp_path, t0, productcode, site, date):\n",
    "    '''Takes an entry from output of generete_laz_download, saves to tmp_path'''\n",
    "\n",
    "    # make sure url is still valid\n",
    "    refresh_url(f, t0, productcode, site, date)\n",
    "    \n",
    "    # name of file to be stored\n",
    "    name = os.path.join(tmp_path, f['name'])\n",
    "    \n",
    "    try:\n",
    "        # Download the laz\n",
    "        download_from_NEON_API(f, tmp_path)\n",
    "        return(None)\n",
    "    except:\n",
    "        return(f['name'])\n",
    "    \n",
    "def extract_bbox(name, tries=1):\n",
    "    cmd = f'pdal info {name}'\n",
    "    try:\n",
    "        reply = subprocess.run(cmd, shell=True, capture_output=True, timeout=20)\n",
    "        if len(reply.stderr) > 0: print(reply.stderr)\n",
    "        meta = json.loads(reply.stdout)\n",
    "        bbox = meta['stats']['bbox']['native']['bbox']\n",
    "        return(bbox)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        if tries < 2:\n",
    "            bbox = extract_bbox(name, tries=tries+1)\n",
    "        else:\n",
    "            return(None)\n",
    "        \n",
    "def execute_pipe(fname, extent, tmp_path, resolution=1):\n",
    "    bbox = extract_bbox(fname)\n",
    "    try:\n",
    "        bounds = ([bbox['minx'], bbox['maxx']], [bbox['miny'], bbox['maxy']])\n",
    "        # if the bounds are at least partially within the extent...\n",
    "        a = bbox['minx'] <= extent['maxx']\n",
    "        b = bbox['maxx'] >= extent['minx']\n",
    "        c = bbox['miny'] <= extent['maxy']\n",
    "        d = bbox['maxy'] >= extent['miny']\n",
    "        if a and b and c and d:\n",
    "            # make and execute the pdal pipeline\n",
    "            pipeline, tile = make_pipe(fname, bounds, tmp_path, resolution=resolution)\n",
    "            count = pipeline.execute()\n",
    "    except TypeError:\n",
    "        print(f'Failed to determin bounds for {fname}!')\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "def origin_warp_if_needed(f):\n",
    "    if not origin_good_1mresolution(f):\n",
    "        warp(f)\n",
    "\n",
    "def origin_good_1mresolution(f):\n",
    "    '''Checks to make sure the origin is centered on 1m resolution'''\n",
    "    cmd = f'gdalinfo {f} | grep \\'Origin =\\''\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True)\n",
    "    if len(result.stderr) > 0: print(result.stderr)\n",
    "        \n",
    "    #meta = json.loads(result.stdout)\n",
    "    x, y = re.search('\\(([^)]+)', str(result.stdout)).group(1).split(',')\n",
    "    x, y = float(x), float(y)\n",
    "    \n",
    "    # make sure x and y are whole numbers\n",
    "    soft_pink_truth = x.is_integer() and y.is_integer()\n",
    "    \n",
    "    return(soft_pink_truth)\n",
    "\n",
    "\n",
    "def warp(f, resolution=1):\n",
    "    '''Runs gdalwarp -tr -tap on the file, f.\n",
    "    This will ensure that the tif pixels are aligned to the origin'''\n",
    "    # Note: this will fail if there are more than one . in the fname\n",
    "    base = f.split('.')[0]\n",
    "    \n",
    "    # warp the pixels to ensure they are on origin\n",
    "    cmd = f'gdalwarp -tr {resolution} {resolution} -tap {f} {base}_w.tiff'\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True)\n",
    "    if len(result.stderr) > 0: print(result.stderr)\n",
    "    \n",
    "    # move new file to old file name\n",
    "    cmd = f'mv {base}_w.tiff {f}'\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True)\n",
    "    if len(result.stderr) > 0: print(result.stderr)\n",
    "\n",
    "def make_mosaic(layer, files, tmp_path):\n",
    "    '''makes a mosaic of tiles'''\n",
    "    # make a vrt for the layer\n",
    "    vrt = gdal.BuildVRT(os.path.join(tmp_path, f'{layer}.vrt'), files)\n",
    "\n",
    "    # make a mosaic for the layer\n",
    "    mosaic = gdal.Translate(os.path.join(tmp_path, f'{layer}.tif'), vrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariance_tifs(productcode, site, date, tmp_path, extent):\n",
    "    # make sure dir exists \n",
    "    os.makedirs(tmp_path, exist_ok=True)\n",
    "\n",
    "    # get list of files to download\n",
    "    t0, laz = generate_laz_download_info(productcode, site, date)\n",
    "\n",
    "    # download the files\n",
    "    print('Downlaoding laz files:')\n",
    "    lazy0 = []\n",
    "    for f in laz:\n",
    "        lazy0.append(delayed(download_laz)(f, tmp_path, t0, productcode, site, date))\n",
    "\n",
    "    with ProgressBar():\n",
    "        fails = compute(*lazy0)\n",
    "\n",
    "    fails = [thing for thing in fails if thing!=None]\n",
    "\n",
    "    # diy glob the files that were actually downloaded\n",
    "    down_laz = [os.path.join(tmp_path,f) for f in os.listdir(tmp_path) if '.laz' in f]\n",
    "\n",
    "    # make the pipelines and run them\n",
    "    print('Making and executing pipeline:')\n",
    "    lazy1 =[]\n",
    "    for f in down_laz:\n",
    "        lazy1.append(delayed(execute_pipe)(fname, extent, tmp_path, resolution=1))\n",
    "\n",
    "    with ProgressBar():\n",
    "        _ = compute(*lazy1)\n",
    "\n",
    "    # make a dict of tiles for each layer\n",
    "    layers = ['Anisotropy', 'DemantkeVerticality', 'Linearity', 'Omnivariance', 'Planarity',\n",
    "              'Scattering', 'SurfaceVariation', 'Verticality']\n",
    "\n",
    "    eigendict ={}\n",
    "    for layer in layers:\n",
    "        eigendict[layer] = [os.path.join(tmp_path,f) for f in os.listdir(tmp_path) if layer in f]\n",
    "\n",
    "    # make sure tifs have pixels aligned to origin, do it in || with dask.\n",
    "    print('Waroing if necessary')\n",
    "    lazy2 = []\n",
    "    for key, val in eigendict.items():\n",
    "        for f in val:\n",
    "              lazy2.append(delayed(origin_warp_if_needed)(f))\n",
    "\n",
    "    with ProgressBar():\n",
    "        _ = compute(*lazy2)\n",
    "\n",
    "    # build vrt, make mosaic for each layer, in ||\n",
    "    print('Making mosaic *\\(-_-)/*')\n",
    "    also_lazy = []\n",
    "    for layer, files in eigendict.items():    \n",
    "          also_lazy.append(delayed(make_mosaic)(layer, files, tmp_path))\n",
    "\n",
    "    with ProgressBar():\n",
    "        _ = compute(*also_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 16.7s\n"
     ]
    }
   ],
   "source": [
    "make_covariance_tifs(productcode, site, date, tmp_path, extent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
